{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "1463 ('Boys, Les (1997)', '01-Jan-1997')                          5\n",
      "1536 ('Aiqing wansui (1994)', '22-Jul-1996')                      4.94\n",
      "814  ('Great Day in Harlem, A (1994)', '01-Jan-1994')             4.889\n",
      "1599 (\"Someone Else's America (1995)\", '10-May-1996')             4.615\n",
      "1500 ('Santa with Muscles (1996)', '08-Nov-1996')                 4.613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Boys, Les (1997)',\n",
       " 'Aiqing wansui (1994)',\n",
       " 'Great Day in Harlem, A (1994)',\n",
       " \"Someone Else's America (1995)\",\n",
       " 'Santa with Muscles (1996)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "from collections import defaultdict\n",
    "from surprise import KNNBaseline\n",
    "from surprise import Dataset\n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "input_user=\"5\"\n",
    "#input(\"Enter User ID:\")\n",
    "\n",
    "\n",
    "def get_items():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = (line[1], line[2])\n",
    "    return rid_to_name\n",
    "\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "algo = KNNBaseline(k=4,sim_options={'name':'cosine','user_base':True,'min_support':5})\n",
    "algo.fit(trainset)\n",
    "\n",
    "testset = trainset.build_anti_testset()\n",
    "testset = filter(lambda x: x[0] == input_user, testset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "top_n = defaultdict(list)\n",
    "for uid, iid, _, est, _ in predictions:\n",
    "    top_n[uid].append((iid, round(est,3)))\n",
    "\n",
    "for uid, user_ratings in top_n.items():\n",
    "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_n[uid] = user_ratings[:5]\n",
    "    \n",
    "item_map=get_items()\n",
    "\n",
    "        \n",
    "# Print the recommended items for each user\n",
    "arr=[]\n",
    "for movie_rid, rating in top_n[input_user]:\n",
    "    arr.append(item_map[movie_rid][0])\n",
    "    print('{:4s} {:<60s} {}'.format(movie_rid, str(item_map[movie_rid]), rating))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Les Boys',\n",
       " 'Aiqing wansui',\n",
       " 'A Great Day in Harlem',\n",
       " \"Someone Else's America\",\n",
       " 'Santa with Muscles']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Formating strings for search in wikidata\n",
    "for k,_ in enumerate(arr):\n",
    "    arr[k]=arr[k][:-6]\n",
    "    if(',' in arr[k]):\n",
    "        temp=arr[k].split(',')\n",
    "        arr[k]=temp[1]+temp[0]\n",
    "    arr[k]=arr[k].strip()\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Les Boys', 'Q3231134'),\n",
       " ('A Great Day in Harlem', 'Q4657171'),\n",
       " (\"Someone Else's America\", 'Q7219297'),\n",
       " ('Santa with Muscles', 'Q1631700')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "API_ENDPOINT = \"https://www.wikidata.org/w/api.php\"\n",
    "\n",
    "films=[]\n",
    "\n",
    "for query in arr:\n",
    "    params = {\n",
    "        'action' : 'wbsearchentities',\n",
    "        'format' : 'json',\n",
    "        'language' : 'en',\n",
    "        'search': query\n",
    "    }\n",
    "    res = requests.get(API_ENDPOINT, params = params)\n",
    "    if res.json()['search']:\n",
    "        for item in res.json()['search']:\n",
    "            if('film' in item['description']):\n",
    "                films.append((query,item['id']))\n",
    "                break\n",
    "films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\")\n",
    "final=[]\n",
    "for item in films:\n",
    "    spaqrql_query = \"\"\"\n",
    "SELECT DISTINCT ?film ?filmLabel (GROUP_CONCAT(DISTINCT ?genreLabel;separator=\", \") as ?genreLabel_shown)\n",
    "(SAMPLE(?year) as ?year_shown)\n",
    "WHERE \n",
    "{                          \n",
    "  ?film wdt:P31 wd:Q11424.\n",
    "  wd:\"\"\"+item[1]+\"\"\" wdt:P136 ?genre.\n",
    "  wd:\"\"\"+item[1]+\"\"\" wdt:P577 ?date.\n",
    "  ?film wdt:P577 ?year.\n",
    "  ?film wdt:P136 ?genre.\n",
    "  FILTER(YEAR(?year)=YEAR(?date))\n",
    "  FILTER(?film != wd:\"\"\"+item[1]+\"\"\")\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\".\n",
    "                         ?genre rdfs:label ?genreLabel.\n",
    "                         ?film rdfs:label ?filmLabel.}\n",
    "}\n",
    "GROUP BY ?film ?filmLabel\n",
    "\"\"\"\n",
    "    sparql.setQuery(spaqrql_query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results=(sparql.query().convert())\n",
    "    final.append((sparql.query().convert()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type number 0 to get movies for film: Les Boys\n",
      "Type number 1 to get movies for film: A Great Day in Harlem\n",
      "Type number 2 to get movies for film: Someone Else's America\n",
      "Type number 3 to get movies for film: Santa with Muscles\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your Number: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film.value</th>\n",
       "      <th>filmLabel.value</th>\n",
       "      <th>genreLabel_shown.value</th>\n",
       "      <th>year_shown.value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>http://www.wikidata.org/entity/Q2309994</td>\n",
       "      <td>Empire Records</td>\n",
       "      <td>tragicomedy</td>\n",
       "      <td>1995-01-01T00:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>http://www.wikidata.org/entity/Q156516</td>\n",
       "      <td>Underground</td>\n",
       "      <td>tragicomedy</td>\n",
       "      <td>1995-04-01T00:00:00Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>http://www.wikidata.org/entity/Q7598722</td>\n",
       "      <td>Q7598722</td>\n",
       "      <td>tragicomedy</td>\n",
       "      <td>1995-01-01T00:00:00Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                film.value filmLabel.value  \\\n",
       "0  http://www.wikidata.org/entity/Q2309994  Empire Records   \n",
       "1   http://www.wikidata.org/entity/Q156516     Underground   \n",
       "2  http://www.wikidata.org/entity/Q7598722        Q7598722   \n",
       "\n",
       "  genreLabel_shown.value      year_shown.value  \n",
       "0            tragicomedy  1995-01-01T00:00:00Z  \n",
       "1            tragicomedy  1995-04-01T00:00:00Z  \n",
       "2            tragicomedy  1995-01-01T00:00:00Z  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=[]\n",
    "for item in final:\n",
    "    output.append(pd.io.json.json_normalize(item['results']['bindings']))\n",
    "\n",
    "for k,_ in enumerate(films):\n",
    "    print(\"Type number\",k,\"to get movies for film:\",films[k][0])\n",
    "i=int(input(\"Your Number:\"))\n",
    "output[i][['film.value', 'filmLabel.value','genreLabel_shown.value','year_shown.value']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
